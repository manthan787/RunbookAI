---
title: Incident Investigation
description: Example of investigating a production incident
---

This example walks through a complete incident investigation using Runbook.

## Scenario

You receive a PagerDuty alert: **High Error Rate - checkout-api (SEV2)**

## Investigation

### Start Investigation

```bash
runbook investigate PD-12345
```

### Phase 1: Triage

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    INCIDENT INVESTIGATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Incident: High Error Rate - checkout-api
Severity: SEV2
Duration: 15 minutes
Triggered: 2024-01-15 15:00 UTC

Phase 1: Triage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ Gathering incident context from PagerDuty...
âœ“ pagerduty_get_incident (245ms)

Alert Details:
  â€¢ Error rate: 5.2% (threshold: 1%)
  â€¢ Affected: checkout-api
  â€¢ Started: 14:52 UTC

Affected Services:
  â€¢ checkout-api (primary)
  â€¢ payment-service (dependency)
  â€¢ PostgreSQL database (infrastructure)

â†’ Searching knowledge base...
âœ“ search_knowledge (189ms)

Relevant Knowledge:
  ğŸ“˜ Runbook: "Database Connection Exhaustion" (85% match)
     Services: checkout-api, payment-service
     Symptoms match: connection timeout, high error rate

  ğŸ“• Post-mortem: "2024-01-15 Checkout Outage" (72% match)
     Root cause: Traffic spike from marketing campaign

  ğŸ“ Architecture: "checkout-api Service"
     Dependencies: PostgreSQL via PgBouncer, Redis
```

### Phase 2: Hypothesize

```
Phase 2: Hypothesize
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Forming hypotheses based on evidence...

Based on symptoms and knowledge base matches:

  H1: Database connection exhaustion [P: 0.45]
      â€¢ Matches "Database Connection Exhaustion" runbook
      â€¢ checkout-api depends on PostgreSQL
      â€¢ Previous similar incident in knowledge base

  H2: Recent deployment introduced bug [P: 0.25]
      â€¢ checkout-api deployed 2 hours ago
      â€¢ Error pattern could indicate code issue

  H3: Payment service degradation [P: 0.15]
      â€¢ checkout-api depends on payment-service
      â€¢ Could cause cascading failures

  H4: Traffic spike overwhelming capacity [P: 0.15]
      â€¢ SEV2 incidents often correlate with traffic
      â€¢ Similar to previous marketing campaign incident
```

### Phase 3: Investigate

```
Phase 3: Investigate
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Testing H1: Database connection exhaustion...
â†’ aws_query (RDS connection metrics)
âœ“ 234ms

  RDS Metrics:
  â”œâ”€ Database: prod-checkout-db
  â”œâ”€ Connections: 95/100 (95% capacity)
  â”œâ”€ Connection Wait Time: 2.3s (baseline: 0.2s)
  â”œâ”€ CPU: 45% (normal)
  â””â”€ Read IOPS: 12,000 (normal)

  Evidence: STRONG
  â€¢ Connections at 95% capacity
  â€¢ Connection wait time 10x baseline
  â€¢ CPU and IOPS normal (not query-related)

  â†³ Branching to investigate cause of connection exhaustion...

Testing H1.1: Traffic spike caused exhaustion...
â†’ aws_query (CloudWatch request metrics)
âœ“ 178ms

  Traffic Metrics:
  â”œâ”€ Current: 3,600 req/min
  â”œâ”€ Baseline: 1,200 req/min
  â”œâ”€ Increase: 3x
  â””â”€ Started: 14:32 UTC

  Source Analysis:
  â”œâ”€ Origin: Organic (not DDoS)
  â”œâ”€ Pattern: Gradual increase
  â””â”€ Correlation: Marketing campaign sent at 14:30 UTC

  Evidence: STRONG
  â€¢ Request rate 3x normal
  â€¢ Started 28 minutes ago
  â€¢ Correlates with marketing campaign

Testing H2: Recent deployment bug...
â†’ aws_query (ECS deployment history)
âœ“ 145ms

  Deployment History:
  â”œâ”€ Last deploy: 6 hours ago (v1.2.2)
  â”œâ”€ Error timeline: Started 28 minutes ago
  â””â”€ Correlation: None

  Evidence: NONE
  â€¢ Last deployment was 6 hours ago
  â€¢ Errors started 28 minutes ago
  â€¢ No temporal correlation

  âœ— Pruning H2: No deployment in error window

Testing H3: Payment service degradation...
â†’ aws_query (ECS service health)
âœ“ 156ms

  payment-service Status:
  â”œâ”€ Tasks: 4/4 running
  â”œâ”€ Health: All healthy
  â”œâ”€ Error rate: 0.1% (normal)
  â””â”€ Latency: 45ms (normal)

  Evidence: NONE
  â€¢ Payment service is healthy
  â€¢ No errors or latency issues

  âœ— Pruning H3: Service healthy

Testing H1.2: Connection pool misconfiguration...
â†’ aws_query (ECS task definition)
âœ“ 134ms

  Pool Configuration:
  â”œâ”€ App pool size: 10 connections/task
  â”œâ”€ Tasks: 4 running
  â”œâ”€ Total possible: 40 connections
  â””â”€ RDS limit: 100 connections

  Analysis:
  â€¢ Pool size is appropriate for normal traffic
  â€¢ But insufficient for 3x traffic spike

  Evidence: WEAK
  â€¢ Config is correct for normal load
  â€¢ Insufficient for current traffic

  â†’ Continue investigating, not root cause
```

### Phase 4: Evaluate

```
Phase 4: Evaluate
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Hypothesis Confidence:

  H1: Database connection exhaustion
      Confidence: 0.92 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ HIGH
      Evidence:
        â€¢ Connections at 95% capacity [STRONG]
        â€¢ Wait time 10x baseline [STRONG]
        â€¢ Runbook match: 85% [BOOST]

      H1.1: Traffic spike as root cause
            Confidence: 0.88 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ HIGH
            Evidence:
              â€¢ 3x traffic increase [STRONG]
              â€¢ Correlates with marketing email [STRONG]

      H1.2: Pool misconfiguration
            Status: PRUNED (contributing factor, not cause)

  H2: Deployment bug
      Status: PRUNED
      Reason: No deployment in error window

  H3: Payment service
      Status: PRUNED
      Reason: Service healthy

  H4: Traffic spike
      Status: MERGED â†’ H1.1
      Reason: Same evidence, combined hypothesis
```

### Phase 5: Conclude

```
Phase 5: Conclude
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    ROOT CAUSE IDENTIFIED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Root Cause: Database connection exhaustion due to traffic spike
Confidence: HIGH (0.92)

Timeline:
  14:30 UTC â”‚ Marketing campaign email sent
  14:32 UTC â”‚ Traffic began increasing (3x)
  14:45 UTC â”‚ Connection pool reached 80% capacity
  14:48 UTC â”‚ Connection wait times started increasing
  14:52 UTC â”‚ First timeout errors in checkout-api
  14:55 UTC â”‚ Error rate exceeded 5% threshold
  15:00 UTC â”‚ PagerDuty alert triggered

Evidence Summary:
  âœ“ RDS connections at 95% capacity
  âœ“ Connection wait time 10x baseline
  âœ“ Request rate 3x normal
  âœ“ Traffic increase correlates with marketing campaign
  âœ“ No recent deployments
  âœ“ Payment service healthy

Contributing Factors:
  â€¢ Connection pool not auto-scaling with traffic
  â€¢ No PgBouncer connection pooler in use
  â€¢ Marketing team didn't notify engineering of campaign

Related Knowledge Applied:
  â€¢ Runbook: "Database Connection Exhaustion" (followed steps 1-4)
  â€¢ Post-mortem: "2024-01-15 Checkout Outage" (similar pattern)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Phase 6: Remediate

```
Phase 6: Remediate
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Suggested Remediation:

Immediate Actions:

  [1] Scale RDS read replicas
      Risk: HIGH
      Impact: Reduce connection pressure by 50%
      Skill: scale-service

      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘                  APPROVAL REQUIRED                     â•‘
      â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
      â•‘  Operation: Add 2 RDS read replicas                    â•‘
      â•‘  Current: 2 replicas                                   â•‘
      â•‘  Target: 4 replicas                                    â•‘
      â•‘                                                        â•‘
      â•‘  Rollback:                                             â•‘
      â•‘  aws rds modify-db-cluster \                          â•‘
      â•‘    --db-cluster-id prod-checkout-db \                 â•‘
      â•‘    --scaling-configuration MinCapacity=2              â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

      [Waiting for Slack approval...]
      âœ“ Approved by @alice (15:05 UTC)

      â†’ Executing scale operation...
      âœ“ Scale initiated (1.2s)
      â†’ Waiting for replicas...
      âœ“ Replicas available (4m 32s)

  [2] Restart checkout-api tasks
      Risk: MEDIUM
      Impact: Clear stale connections
      Skill: restart-service

      [Approval received via Slack]

      â†’ Restarting tasks...
      âœ“ 4/4 tasks restarted (2m 15s)

Long-term Recommendations:
  â€¢ Implement PgBouncer for connection pooling
  â€¢ Add auto-scaling for RDS read replicas
  â€¢ Create marketing â†’ engineering notification process
  â€¢ Add traffic forecasting for campaigns

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    INVESTIGATION COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Duration: 8 minutes 34 seconds
Actions Taken: 2 (with approval)
Status: Resolved

Post-incident:
  â€¢ Notes added to PagerDuty incident
  â€¢ Investigation logged to scratchpad
  â€¢ Recommendations documented

Would you like to generate a post-mortem? [y/N]
```

## Key Takeaways

1. **Knowledge integration** - The runbook and post-mortem matches significantly improved hypothesis formation
2. **Systematic testing** - Each hypothesis was tested with specific queries
3. **Evidence-based pruning** - Hypotheses without evidence were quickly eliminated
4. **Approved remediation** - Actions required explicit approval before execution
5. **Full audit trail** - Every step was logged for review
